{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7be5fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from random import sample, shuffle\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "4cfa9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, directory, batch_size=32, labels=None, shuffle=True, sample_size=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.dir = directory\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_size = sample_size\n",
    "        self._files = self.__get_images_from_directory(directory)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._files) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch = self._files[index*self.batch_size:index*self.batch_size+self.batch_size]\n",
    "        \n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            shuffle(self._files)\n",
    "        \n",
    "        \n",
    "    def __get_data(self, batch):\n",
    "        X = np.empty((self.batch_size, 128, 512, 1))\n",
    "\n",
    "        for i, file in enumerate(batch):\n",
    "            path = self.dir + file\n",
    "            img = tf.keras.preprocessing.image.load_img(path, color_mode='grayscale')\n",
    "            scale = 1./255\n",
    "            X[i,] = tf.convert_to_tensor(scale*np.array(tf.keras.preprocessing.image.img_to_array(img))) \n",
    "            \n",
    "        y = X\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def iter(self, num):\n",
    "    \n",
    "        return self.__getitem__(num)\n",
    "    \n",
    "    def __get_images_from_directory(self, directory):\n",
    "        files = os.listdir(directory)\n",
    "        if self.shuffle:\n",
    "            shuffle(files)t\n",
    "        \n",
    "        if self.sample_size != None:\n",
    "            files = sample(files, self.sample_size)\n",
    "        \n",
    "        return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "dc0bb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = DataGenerator(directory='data/Spotify/pngs/', batch_size=32, sample_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5aa7fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout, Reshape, Conv2DTranspose, BatchNormalization, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "img_width = 512\n",
    "img_height = 128\n",
    "kernel_size = (5,5)\n",
    "strides = (2,2)\n",
    "\n",
    "\n",
    "class Autoencoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Sequential([\n",
    "            Conv2D(input_shape=(img_height, img_width, 1), filters=32, kernel_size=kernel_size, padding=\"same\", strides=strides, activation='relu'),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2D(filters=64, kernel_size=kernel_size, padding=\"same\", strides=strides, activation='relu'),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2D(filters=128, kernel_size=kernel_size, padding=\"same\", strides=strides, activation='relu'),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2D(filters=256, kernel_size=kernel_size, padding=\"same\",strides=strides, activation='relu'),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Flatten(),\n",
    "            Dense(units=latent_dim,)\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            Dense(units=65536, activation='relu'),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Reshape(target_shape=(8,32,256)),\n",
    "            Conv2DTranspose(filters=256, kernel_size=kernel_size, strides=strides, padding=\"same\", activation=\"relu\"),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2DTranspose(filters=128, kernel_size=kernel_size, strides=strides, padding=\"same\", activation=\"relu\"),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2DTranspose(filters=64, kernel_size=kernel_size,  strides=strides, padding=\"same\", activation=\"relu\"),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2DTranspose(filters=32, kernel_size=kernel_size,  strides=strides, padding=\"same\", activation=\"relu\"),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2DTranspose(filters=1, kernel_size=kernel_size, padding=\"same\", activation='sigmoid'),\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "class Autoencoder2(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder2, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Sequential([\n",
    "            Conv2D(input_shape=(img_height, img_width, 1), filters=32, kernel_size=kernel_size, padding=\"same\", activation='relu'),\n",
    "            MaxPool2D(pool_size=strides),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2D(filters=64, kernel_size=kernel_size, padding=\"same\", activation='relu'),\n",
    "            MaxPool2D(pool_size=strides),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2D(filters=128, kernel_size=kernel_size, padding=\"same\", activation='relu'),\n",
    "            MaxPool2D(pool_size=strides),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2D(filters=256, kernel_size=kernel_size, padding=\"same\", activation='relu'),\n",
    "            MaxPool2D(pool_size=strides),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Flatten(),\n",
    "            Dense(units=latent_dim,)\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            Dense(units=65536, activation='relu'),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Reshape(target_shape=(8,32,256)),\n",
    "            Conv2DTranspose(filters=256, kernel_size=kernel_size, padding=\"same\", activation=\"relu\"),\n",
    "            UpSampling2D(size=strides),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2DTranspose(filters=128, kernel_size=kernel_size, padding=\"same\", activation=\"relu\"),\n",
    "            UpSampling2D(size=strides),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2DTranspose(filters=64, kernel_size=kernel_size,  padding=\"same\", activation=\"relu\"),\n",
    "            UpSampling2D(size=strides),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2DTranspose(filters=32, kernel_size=kernel_size,  padding=\"same\", activation=\"relu\"),\n",
    "            UpSampling2D(size=strides),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2DTranspose(filters=1, kernel_size=kernel_size, padding=\"same\", activation='sigmoid'),\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "autoencoder = Autoencoder(256)\n",
    "autoencoder2 = Autoencoder2(256)\n",
    "\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "\n",
    "autoencoder.compile(optimizer=opt, loss=tf.keras.losses.mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "f9374c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 256, 32)\n",
      "(None, 64, 256, 32)\n",
      "(None, 32, 128, 64)\n",
      "(None, 32, 128, 64)\n",
      "(None, 16, 64, 128)\n",
      "(None, 16, 64, 128)\n",
      "(None, 8, 32, 256)\n",
      "(None, 8, 32, 256)\n",
      "(None, 65536)\n",
      "(None, 256)\n",
      "(None, 65536)\n",
      "(None, 65536)\n",
      "(None, 8, 32, 256)\n",
      "(None, 16, 64, 256)\n",
      "(None, 16, 64, 256)\n",
      "(None, 32, 128, 128)\n",
      "(None, 32, 128, 128)\n",
      "(None, 64, 256, 64)\n",
      "(None, 64, 256, 64)\n",
      "(None, 128, 512, 32)\n",
      "(None, 128, 512, 32)\n",
      "(None, 128, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in autoencoder.layers:\n",
    "    for sublayer in layer.layers:\n",
    "        print(sublayer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24dcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "207/312 [==================>...........] - ETA: 4:25 - loss: 0.0277"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.fit(test_gen, batch_size=32, epochs=20)\n",
    "hist2 = autoencoder2.fit(test_gen, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/Spotify/pngs/'\n",
    "files = os.listdir(base_path)\n",
    "\n",
    "test_img = np.array(Image.open(base_path + files[6788]))\n",
    "test_img = test_img * 1./255\n",
    "print(test_img.shape)\n",
    "test_img_reshape = test_img.reshape(1, img_height, img_width, 1)\n",
    "\n",
    "prediction = autoencoder(test_img_reshape)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(test_img)\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(np.array(prediction[0]*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/Spotify/pngs/'\n",
    "files = os.listdir(base_path)\n",
    "\n",
    "test_img = np.array(Image.open(base_path + files[6788]))\n",
    "test_img = test_img * 1./255\n",
    "print(test_img.shape)\n",
    "test_img_reshape = test_img.reshape(1, img_height, img_width, 1)\n",
    "\n",
    "prediction = autoencoder2(test_img_reshape)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(test_img)\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(np.array(prediction[0]*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aff606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
